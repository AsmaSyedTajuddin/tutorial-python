{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Examples</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Example #1: Load A Large CSV</strong>\n",
    "\n",
    "In order to run this example, you will need to set up SQL Server by creating the staging table and the view.\n",
    "\n",
    "In the SQL directory of the source code directory SQL\\33 Load Large CSVs Into Staging, you will find two files sequentially named. Open them in SSMS and run them in the order specified by their file name. First the table, then the view.\n",
    "\n",
    "Now that we are good to go. We are going to take the large Eurostat data that we compiled, and shoehorn it into a table.\n",
    "\n",
    "In this example, I am going to introduce some feedback mechanisms in the form of timestamps. You can use these to understand how long the processes is taking and where the process is in the execution.\n",
    "\n",
    "Indexes slow the load of database tables. For small amounts of data, that is no big deal. When loading large files, you need to drop any indexes first. Once the file is loaded, you then rebuild any indexes that you dropped. \n",
    "\n",
    "This, of course, is a long running process. However, it is much faster than other methods.\n",
    "\n",
    "<strong>Script Performance</strong>\n",
    "\n",
    "This is not a toy example and it is entirely possible you could choke your machine. On my box, the script took about 30 minutes to load the data. My machine specs are below.\n",
    "\n",
    "Processor: Intel® Core™ i5-4590 CPU @ 3.30GHz<br>\n",
    "RAM: 16.0 GB<br>\n",
    "System type: 64-bit Operating System, x64-based processor<br>\n",
    "\n",
    "If your system has less RAM, expect the process to take longer. If your system performance is significantly less than what is stated above, do not attempt to run this script with the sample file. Instead, cope a file from the FileLoopExample folder and use that instead. Either rename the file or change the value of the file_name variable.\n",
    "\n",
    "<strong>Troubleshooting</strong>\n",
    "\n",
    "Before you run this example, you may want to review <a href=\"https://tutorials.massstreetuniversity.com/transact-sql/solutions/troubleshoot-queries.html\">Lesson 56. Troubleshooting Long Running Queries</a> from the Practical T-SQL Pocket Guide For Beginners.\n",
    "\n",
    "<strong>Viewing Results</strong>\n",
    "\n",
    "When the process has completed, you can view the results by running the SQL queries found after the Python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import what you need and set up your file variables.\n",
    "import os\n",
    "import pyodbc as db\n",
    "import time\n",
    "\n",
    "if not 'script_dir' in globals():\n",
    "    script_dir = os.getcwd()\n",
    "data_directory = 'data\\\\'\n",
    "source_directory = 'CombineCSVExample\\\\'\n",
    "file_name = 'EurostatDataCombined.csv'\n",
    "source_path = os.path.join(script_dir, data_directory,source_directory, file_name)\n",
    "\n",
    "#Build SQL Statements\n",
    "drop_index_sql = 'ALTER TABLE [euro].[EurostatData] DROP CONSTRAINT [PK_EurostatData] WITH ( ONLINE = OFF )'\n",
    "\n",
    "add_index_sql = 'ALTER TABLE [euro].[EurostatData] ADD  CONSTRAINT [PK_EurostatData] PRIMARY KEY CLUSTERED'\n",
    "add_index_sql = add_index_sql + '([ETLKey] ASC) WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF,' \n",
    "add_index_sql = add_index_sql + 'SORT_IN_TEMPDB = OFF, IGNORE_DUP_KEY = OFF, ONLINE = OFF, ALLOW_ROW_LOCKS = ON,'\n",
    "add_index_sql = add_index_sql + 'ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]'\n",
    "\n",
    "sql = \"BULK INSERT EurostatData FROM '\" + source_path + \"' WITH (FIELDTERMINATOR = '|', ROWTERMINATOR = '0x0a', FIRSTROW = 2, TABLOCK, BATCHSIZE = 100000)\"\n",
    "\n",
    "#Set up the connection.\n",
    "print('Connecting to SQL Server database' + time.strftime(' %H:%M:%S'))\n",
    "connection_string = 'DSN=ETL;'\n",
    "conn = db.connect(connection_string)\n",
    "print('Preparing database for update' + time.strftime(' %H:%M:%S'))\n",
    "csr = conn.cursor()\n",
    "\n",
    "\n",
    "#now let's load the file\n",
    "print('Begin processing {}.'.format(file_name) + time.strftime(' %H:%M:%S'))\n",
    "csr.execute('TRUNCATE TABLE euro.EurostatData')\n",
    "csr.execute(drop_index_sql)\n",
    "print('Updating staging')\n",
    "csr.execute(sql)\n",
    "csr.execute(add_index_sql)\n",
    "print('Processing file {} complete.'.format(file_name) + time.strftime(' %H:%M:%S'))\n",
    "conn.commit()\n",
    "csr.close()\n",
    "conn.close()\n",
    "\n",
    "print('Complete: Processing Data'  + time.strftime(' %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE ODS\n",
    "\n",
    "SELECT COUNT(*) FROM euro.EurostatData --31,599,999\n",
    "\n",
    "SELECT TOP 100 * FROM euro.EurostatData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2020, Mass Street Analytics, LLC. All Rights Reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
